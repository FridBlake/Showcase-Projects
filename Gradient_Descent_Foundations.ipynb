{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Using partial derivatives, this gradient descent algorithm solves the equation ax = b for x. It gives an extremely close answer, in most cases.\n",
        "\n",
        "This is intended to be a prototype of linear regression, and goes to show the stepping stones for machine learning."
      ],
      "metadata": {
        "id": "wei-D7yI2Bnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dsczvpa3CX-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dda641-bce9-4a1f-80a9-4d627e9b5c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter A's value: 0.5\n",
            "Enter B's value: 4\n",
            "Enter the number of iterations: 1000\n",
            "Enter the learning rate: 0.01\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The value of X has been found as: 7.953422219948172.\n",
            "This may be a close approximate.\n",
            "\n",
            "If the value is not satisfactory, please change the number of iterations and learning rate.\n"
          ]
        }
      ],
      "source": [
        "def gradientDescent(inp, out, iters=5000, lr=0.001):\n",
        "  weight = 1\n",
        "  for i in range(0, iters):\n",
        "    prediction = inp * weight\n",
        "    slope = 2 * inp * (out-prediction) #d(SSR)/dw\n",
        "    step = lr * slope  # learning rate * d(SSR)/dw\n",
        "    weight += step # w = w + step \n",
        "\n",
        "  return weight\n",
        "\n",
        "inp = float(input(\"Enter A's value: \"))\n",
        "out = float(input(\"Enter B's value: \"))\n",
        "iters = int(input(\"Enter the number of iterations: \"))\n",
        "lr = float(input(\"Enter the learning rate: \"))\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(f\"\"\"The value of X has been found as: {gradientDescent(inp, out, iters, lr)}.\\nThis may be a close approximate.\\n\n",
        "If the value is not satisfactory, please change the number of iterations and learning rate.\"\"\")\n"
      ]
    }
  ]
}